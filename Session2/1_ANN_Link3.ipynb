{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install keras_tuner"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CzL7vMnYn7Kq",
        "outputId": "9218a2e8-e160-4c8b-e80e-171f2ac3950e"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: keras_tuner in /usr/local/lib/python3.10/dist-packages (1.4.7)\n",
            "Requirement already satisfied: keras in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (3.5.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (24.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (2.32.3)\n",
            "Requirement already satisfied: kt-legacy in /usr/local/lib/python3.10/dist-packages (from keras_tuner) (1.0.5)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (1.26.4)\n",
            "Requirement already satisfied: rich in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (13.9.4)\n",
            "Requirement already satisfied: namex in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.0.8)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (3.12.1)\n",
            "Requirement already satisfied: optree in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.13.1)\n",
            "Requirement already satisfied: ml-dtypes in /usr/local/lib/python3.10/dist-packages (from keras->keras_tuner) (0.4.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->keras_tuner) (2024.8.30)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from optree->keras->keras_tuner) (4.12.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich->keras->keras_tuner) (2.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich->keras->keras_tuner) (0.1.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GDwEy4HECzy"
      },
      "source": [
        "Importing and exploring the dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "collapsed": true,
        "id": "MrmQKC6-kDYD",
        "outputId": "3d97de5c-8313-4a34-c290-ad97fd16731e"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   age           job  marital  education default  balance housing loan  \\\n",
              "0   58    management  married   tertiary      no     2143     yes   no   \n",
              "1   44    technician   single  secondary      no       29     yes   no   \n",
              "2   33  entrepreneur  married  secondary      no        2     yes  yes   \n",
              "3   47   blue-collar  married    unknown      no     1506     yes   no   \n",
              "4   33       unknown   single    unknown      no        1      no   no   \n",
              "\n",
              "   contact  day month  duration  campaign  pdays  previous poutcome   y  \n",
              "0  unknown    5   may       261         1     -1         0  unknown  no  \n",
              "1  unknown    5   may       151         1     -1         0  unknown  no  \n",
              "2  unknown    5   may        76         1     -1         0  unknown  no  \n",
              "3  unknown    5   may        92         1     -1         0  unknown  no  \n",
              "4  unknown    5   may       198         1     -1         0  unknown  no  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-d68df0e5-6dac-4c5c-a3c3-9902e19043df\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>age</th>\n",
              "      <th>job</th>\n",
              "      <th>marital</th>\n",
              "      <th>education</th>\n",
              "      <th>default</th>\n",
              "      <th>balance</th>\n",
              "      <th>housing</th>\n",
              "      <th>loan</th>\n",
              "      <th>contact</th>\n",
              "      <th>day</th>\n",
              "      <th>month</th>\n",
              "      <th>duration</th>\n",
              "      <th>campaign</th>\n",
              "      <th>pdays</th>\n",
              "      <th>previous</th>\n",
              "      <th>poutcome</th>\n",
              "      <th>y</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>58</td>\n",
              "      <td>management</td>\n",
              "      <td>married</td>\n",
              "      <td>tertiary</td>\n",
              "      <td>no</td>\n",
              "      <td>2143</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>261</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>44</td>\n",
              "      <td>technician</td>\n",
              "      <td>single</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>29</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>151</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>33</td>\n",
              "      <td>entrepreneur</td>\n",
              "      <td>married</td>\n",
              "      <td>secondary</td>\n",
              "      <td>no</td>\n",
              "      <td>2</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>76</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>47</td>\n",
              "      <td>blue-collar</td>\n",
              "      <td>married</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1506</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>92</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>33</td>\n",
              "      <td>unknown</td>\n",
              "      <td>single</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "      <td>1</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>unknown</td>\n",
              "      <td>5</td>\n",
              "      <td>may</td>\n",
              "      <td>198</td>\n",
              "      <td>1</td>\n",
              "      <td>-1</td>\n",
              "      <td>0</td>\n",
              "      <td>unknown</td>\n",
              "      <td>no</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-d68df0e5-6dac-4c5c-a3c3-9902e19043df')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-d68df0e5-6dac-4c5c-a3c3-9902e19043df button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-d68df0e5-6dac-4c5c-a3c3-9902e19043df');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-965ccffd-88dd-4513-a357-75d18a1fe36c\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-965ccffd-88dd-4513-a357-75d18a1fe36c')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-965ccffd-88dd-4513-a357-75d18a1fe36c button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "data",
              "summary": "{\n  \"name\": \"data\",\n  \"rows\": 45211,\n  \"fields\": [\n    {\n      \"column\": \"age\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 10,\n        \"min\": 18,\n        \"max\": 95,\n        \"num_unique_values\": 77,\n        \"samples\": [\n          35,\n          34,\n          53\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"job\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"housemaid\",\n          \"unemployed\",\n          \"management\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"marital\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"married\",\n          \"single\",\n          \"divorced\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"education\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"secondary\",\n          \"primary\",\n          \"tertiary\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"default\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"balance\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3044,\n        \"min\": -8019,\n        \"max\": 102127,\n        \"num_unique_values\": 7168,\n        \"samples\": [\n          3276,\n          43\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"housing\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"no\",\n          \"yes\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"loan\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contact\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"unknown\",\n          \"cellular\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"day\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 8,\n        \"min\": 1,\n        \"max\": 31,\n        \"num_unique_values\": 31,\n        \"samples\": [\n          1,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"month\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 12,\n        \"samples\": [\n          \"apr\",\n          \"mar\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"duration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 257,\n        \"min\": 0,\n        \"max\": 4918,\n        \"num_unique_values\": 1573,\n        \"samples\": [\n          835,\n          1135\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"campaign\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 3,\n        \"min\": 1,\n        \"max\": 63,\n        \"num_unique_values\": 48,\n        \"samples\": [\n          41,\n          27\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"pdays\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 100,\n        \"min\": -1,\n        \"max\": 871,\n        \"num_unique_values\": 559,\n        \"samples\": [\n          249,\n          551\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"previous\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2,\n        \"min\": 0,\n        \"max\": 275,\n        \"num_unique_values\": 41,\n        \"samples\": [\n          17,\n          9\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"poutcome\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 4,\n        \"samples\": [\n          \"failure\",\n          \"success\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"y\",\n      \"properties\": {\n        \"dtype\": \"category\",\n        \"num_unique_values\": 2,\n        \"samples\": [\n          \"yes\",\n          \"no\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ],
      "source": [
        "# importing pandas module\n",
        "import pandas as pd\n",
        "# importing dataset\n",
        "data = pd.read_csv('./dataset/bank+marketing/bank/bank-full.csv', sep=';')\n",
        "# heading\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dtrl-JdhTsIo"
      },
      "source": [
        "Next, let us use the info() method to find more information about the dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "execution": {
          "iopub.execute_input": "2024-04-20T11:27:06.958844Z",
          "iopub.status.busy": "2024-04-20T11:27:06.958603Z",
          "iopub.status.idle": "2024-04-20T11:27:09.747568Z",
          "shell.execute_reply": "2024-04-20T11:27:09.746670Z"
        },
        "id": "Pa1Pf37RhEYN",
        "outputId": "23c57bdf-c05c-44e0-de64-3cbaa1949908"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 45211 entries, 0 to 45210\n",
            "Data columns (total 17 columns):\n",
            " #   Column     Non-Null Count  Dtype \n",
            "---  ------     --------------  ----- \n",
            " 0   age        45211 non-null  int64 \n",
            " 1   job        45211 non-null  object\n",
            " 2   marital    45211 non-null  object\n",
            " 3   education  45211 non-null  object\n",
            " 4   default    45211 non-null  object\n",
            " 5   balance    45211 non-null  int64 \n",
            " 6   housing    45211 non-null  object\n",
            " 7   loan       45211 non-null  object\n",
            " 8   contact    45211 non-null  object\n",
            " 9   day        45211 non-null  int64 \n",
            " 10  month      45211 non-null  object\n",
            " 11  duration   45211 non-null  int64 \n",
            " 12  campaign   45211 non-null  int64 \n",
            " 13  pdays      45211 non-null  int64 \n",
            " 14  previous   45211 non-null  int64 \n",
            " 15  poutcome   45211 non-null  object\n",
            " 16  y          45211 non-null  object\n",
            "dtypes: int64(7), object(10)\n",
            "memory usage: 5.9+ MB\n"
          ]
        }
      ],
      "source": [
        "# printing info dataset\n",
        "data.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nqN-obhZENmw"
      },
      "source": [
        "Notice that we have 45211 observations, and most columns are object types. We will now use the LabelEncoding method to change the typed object values into numeric ones."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "zMv9WIxOhHRl"
      },
      "outputs": [],
      "source": [
        "# importing the module\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# creating labing encoding object\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# Encode labels in multiple columns\n",
        "data['job']= label_encoder.fit_transform(data['job'])\n",
        "data['marital']= label_encoder.fit_transform(data['marital'])\n",
        "data['education']= label_encoder.fit_transform(data['education'])\n",
        "data['default']= label_encoder.fit_transform(data['default'])\n",
        "data['housing']= label_encoder.fit_transform(data['housing'])\n",
        "data['housing']= label_encoder.fit_transform(data['housing'])\n",
        "data['loan']= label_encoder.fit_transform(data['loan'])\n",
        "data['contact']= label_encoder.fit_transform(data['contact'])\n",
        "data['month']= label_encoder.fit_transform(data['month'])\n",
        "data['poutcome']= label_encoder.fit_transform(data['poutcome'])\n",
        "data['y']= label_encoder.fit_transform(data['y'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEchlf2KkXFv"
      },
      "source": [
        "Let us plot the bar chart for the output values using Matplotlib:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 465
        },
        "id": "baBpMQ5shIyj",
        "outputId": "a1fbf157-6101-453f-9db3-56f1fb43ae06"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x500 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# importing matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "# plotting\n",
        "fig = plt.figure(figsize = (10, 5))\n",
        "#  Bar plot\n",
        "plt.bar(['No',\"Yes\"], data.y.value_counts(), color ='green',\n",
        "        width = 0.8)\n",
        "# labeling\n",
        "plt.xlabel(\"Classes\")\n",
        "plt.ylabel(\"Values\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W1reKFsvUGMU"
      },
      "source": [
        "### Splitting dataset\n",
        "Now, we will divide the dataset into input values and output classes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "9aWT0pPMlBTs"
      },
      "outputs": [],
      "source": [
        "# splitting dataset\n",
        "X = data.drop('y', axis=1)\n",
        "y = data['y']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sBgHSQLSUJSp"
      },
      "source": [
        "Let us now split the dataset set input testing and training data.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "Zzr_UyaIA62Z"
      },
      "outputs": [],
      "source": [
        "# importing the module\n",
        "from sklearn.model_selection import train_test_split\n",
        "# splitting into training data and test dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y-KXAC3zEVyR"
      },
      "source": [
        "As you can see, we have assigned 70% of the data to the training and the remaining 30% to the testing.\n",
        "### Building neural network model for binary classification using TensorFlow\n",
        "Now, we will use TensorFlow to build a neural network for binary classification."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "9dVSPBvVUROH"
      },
      "outputs": [],
      "source": [
        "# importing required module\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "from tensorflow.keras import Sequential\n",
        "# defining neural network model\n",
        "model = Sequential()\n",
        "# adding input layer with 16 nodes, specifying the input shape\n",
        "model.add(InputLayer(shape=(16,))) # Corrected line: Providing input_shape as a tuple\n",
        "# adding hidden layer with 10 nodes\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
        "# adding output layer to neural network model\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "88K44TFUUU7U"
      },
      "source": [
        "Compiling dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "id": "oMpwb5AzUTOg"
      },
      "outputs": [],
      "source": [
        "# compile the model with loss function binary_crossentropy\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rx1T6mC6UWYS"
      },
      "source": [
        "As you can see, we have used Adam as an n-optimizer and binary_crossentropy as the loss function. The binary_crossentropy function is used in binary classification and computes the cross-entropy loss between true and predicted labels.\n",
        "\n",
        "Now, it is time to train the model using the training dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0PEtZnYOUXvD",
        "outputId": "5eb341b6-d70c-4ebb-8edc-2f09578559f3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.6971 - loss: 11.0524\n",
            "Epoch 2/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8681 - loss: 0.6333\n",
            "Epoch 3/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8699 - loss: 0.5257\n",
            "Epoch 4/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8761 - loss: 0.4645\n",
            "Epoch 5/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8734 - loss: 0.4988\n",
            "Epoch 6/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8744 - loss: 0.4562\n",
            "Epoch 7/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8776 - loss: 0.4427\n",
            "Epoch 8/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8795 - loss: 0.3845\n",
            "Epoch 9/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.8767 - loss: 0.3668\n",
            "Epoch 10/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4ms/step - accuracy: 0.8686 - loss: 0.4510\n",
            "Epoch 11/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.8743 - loss: 0.3914\n",
            "Epoch 12/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 1ms/step - accuracy: 0.8770 - loss: 0.3722\n",
            "Epoch 13/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8825 - loss: 0.3631\n",
            "Epoch 14/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8830 - loss: 0.3647\n",
            "Epoch 15/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8850 - loss: 0.3424\n",
            "Epoch 16/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8769 - loss: 0.3941\n",
            "Epoch 17/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8821 - loss: 0.3546\n",
            "Epoch 18/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8775 - loss: 0.3681\n",
            "Epoch 19/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.3606\n",
            "Epoch 20/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8783 - loss: 0.3690\n",
            "Epoch 21/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8802 - loss: 0.3669\n",
            "Epoch 22/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8834 - loss: 0.3525\n",
            "Epoch 23/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8802 - loss: 0.3364\n",
            "Epoch 24/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8835 - loss: 0.3506\n",
            "Epoch 25/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8840 - loss: 0.3271\n",
            "Epoch 26/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8814 - loss: 0.3629\n",
            "Epoch 27/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8799 - loss: 0.3430\n",
            "Epoch 28/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8805 - loss: 0.3566\n",
            "Epoch 29/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8784 - loss: 0.3807\n",
            "Epoch 30/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8834 - loss: 0.3138\n",
            "Epoch 31/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.3241\n",
            "Epoch 32/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8820 - loss: 0.3505\n",
            "Epoch 33/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8819 - loss: 0.3318\n",
            "Epoch 34/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8794 - loss: 0.3713\n",
            "Epoch 35/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8863 - loss: 0.3204\n",
            "Epoch 36/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8844 - loss: 0.3918\n",
            "Epoch 37/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8856 - loss: 0.3084\n",
            "Epoch 38/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8884 - loss: 0.2979\n",
            "Epoch 39/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8843 - loss: 0.3138\n",
            "Epoch 40/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8870 - loss: 0.3161\n",
            "Epoch 41/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8832 - loss: 0.3477\n",
            "Epoch 42/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.8879 - loss: 0.2967\n",
            "Epoch 43/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8850 - loss: 0.3119\n",
            "Epoch 44/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8910 - loss: 0.2844\n",
            "Epoch 45/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8842 - loss: 0.3108\n",
            "Epoch 46/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8855 - loss: 0.3061\n",
            "Epoch 47/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8879 - loss: 0.2988\n",
            "Epoch 48/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8815 - loss: 0.3136\n",
            "Epoch 49/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8885 - loss: 0.3008\n",
            "Epoch 50/50\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8849 - loss: 0.3043\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a28d32421a0>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ],
      "source": [
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M6ucRAw3UZ7m"
      },
      "source": [
        "We have fixed the number of epochs to 50. An epoch means training the neural network with all the training data for one cycle. You can change the number of epochs to get an optimum solution.\n",
        "### Evaluating the trained model\n",
        "Now we will use the testing data to evaluate the model’s performance. Let us use the testing data to make predictions using our trained model and evaluate the model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjB6zssSUbTI",
        "outputId": "270a17f7-290d-4480-c2a7-bbd0f1212d49"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - accuracy: 0.8764 - loss: 0.3123\n",
            "Test Accuracy: 0.8736360669136047\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model with test dataset\n",
        "evaluate = model.evaluate(X_test, y_test)\n",
        "print('Test Accuracy:', evaluate[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vbPxcHMnV3fh"
      },
      "source": [
        "The above output shows that our model could correctly classify 85% of the testing dataset.\n",
        "\n",
        "### Parameter tuning to find the optimum number of nodes and epochs\n",
        "Now, we will learn how to find the optimum number of nodes in the hidden layer and epoch value. We will use the Keras parameter tunning method known as Hyperband tunning.\n",
        "\n",
        "We will first create a function that will initialize our model for binary classification with a maximum and a minimum number of nodes in the hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "eNGqH9_uV-xF"
      },
      "outputs": [],
      "source": [
        "# importing the module\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.layers import InputLayer\n",
        "\n",
        "# function to create model\n",
        "def model_builder(hp):\n",
        "    # initializaing the classification model\n",
        "    model = keras.Sequential()\n",
        "    # Providing input_shape as a tuple (16,)\n",
        "    model.add(InputLayer(shape=(16,)))  # Changed line\n",
        "    # specifying the maximum and minimum nodes\n",
        "    hp_units = hp.Int('units', min_value=5, max_value=100)\n",
        "    model.add(keras.layers.Dense(units=hp_units, activation='relu'))\n",
        "    model.add(keras.layers.Dense(1, activation='sigmoid'))\n",
        "    # comppiling the model with loss function binary crossentropy\n",
        "    model.compile(optimizer='adam',\n",
        "                    loss='binary_crossentropy',\n",
        "                    metrics=['accuracy'])\n",
        "    # return classification model\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5WzZhUDeWAT5"
      },
      "source": [
        "Let us initialize the hyperband tunning from the Keras module.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xr75jVIO7LLc",
        "outputId": "2b2f8bc2-d448-4aea-f94f-516e240664ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Reloading Tuner from ./untitled_project/tuner0.json\n"
          ]
        }
      ],
      "source": [
        "# importing the module\n",
        "import keras_tuner as kt\n",
        "import tensorflow as tf\n",
        "# calling the function using hyperband\n",
        "tuner = kt.Hyperband(model_builder,\n",
        "                     objective='val_accuracy',\n",
        "                     max_epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fu_CAwEV6sFy"
      },
      "source": [
        "The Hyperband tuning algorithm uses adaptive resource allocation and early stopping to converge quickly on a high-performing model. It ensures that our model is not overfitted and stops the iterations once a specified result is achieved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "gqayl7OnXaEo"
      },
      "outputs": [],
      "source": [
        "# early stopping\n",
        "stop_early = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=5)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-pHxu3X26vs0"
      },
      "source": [
        "We will start the tuner search and find the optimum number of nodes in the hidden layer."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjOCnIYdXb7R",
        "outputId": "5829a9a8-1c4f-4b5a-b1bb-26dbb494dead"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimin number of nodes in hidden layer are : 68\n"
          ]
        }
      ],
      "source": [
        "# initializing the tunner\n",
        "tuner.search(X,y, epochs=100, validation_split=0.2, callbacks=[stop_early])\n",
        "# Get the optimal hyperparameters\n",
        "best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]\n",
        "print(\"Optimin number of nodes in hidden layer are :\", best_hps.get('units'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jepE7UM36xYy"
      },
      "source": [
        "As you can see, the optimum number of nodes in the hidden layer is 54. Now, let us also find the optimum number of epochs using the parameters returned by the tuner search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CdffKjsBi9m7",
        "outputId": "ceddc444-d8be-433e-9e16-c9c804d11a5d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 5ms/step - accuracy: 0.8753 - loss: 4.8943 - val_accuracy: 0.6984 - val_loss: 4.7183\n",
            "Epoch 2/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.9139 - loss: 0.8982 - val_accuracy: 0.6846 - val_loss: 4.0057\n",
            "Epoch 3/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9143 - loss: 0.7268 - val_accuracy: 0.6842 - val_loss: 11.4905\n",
            "Epoch 4/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9185 - loss: 0.6946 - val_accuracy: 0.7115 - val_loss: 2.8696\n",
            "Epoch 5/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9154 - loss: 0.6141 - val_accuracy: 0.6843 - val_loss: 5.2905\n",
            "Epoch 6/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9163 - loss: 0.5792 - val_accuracy: 0.7274 - val_loss: 0.9381\n",
            "Epoch 7/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9199 - loss: 0.6789 - val_accuracy: 0.7178 - val_loss: 1.7553\n",
            "Epoch 8/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9191 - loss: 0.5827 - val_accuracy: 0.6847 - val_loss: 3.4394\n",
            "Epoch 9/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9217 - loss: 0.5200 - val_accuracy: 0.7101 - val_loss: 1.1038\n",
            "Epoch 10/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9106 - loss: 0.8634 - val_accuracy: 0.6999 - val_loss: 6.3407\n",
            "Epoch 11/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9167 - loss: 0.6058 - val_accuracy: 0.6983 - val_loss: 2.5063\n",
            "Epoch 12/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9189 - loss: 0.5214 - val_accuracy: 0.6922 - val_loss: 3.2821\n",
            "Epoch 13/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.4623 - val_accuracy: 0.6897 - val_loss: 2.5832\n",
            "Epoch 14/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9248 - loss: 0.5054 - val_accuracy: 0.7045 - val_loss: 1.0406\n",
            "Epoch 15/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9183 - loss: 0.4953 - val_accuracy: 0.7033 - val_loss: 1.2734\n",
            "Epoch 16/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9213 - loss: 0.4799 - val_accuracy: 0.7003 - val_loss: 1.7231\n",
            "Epoch 17/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9199 - loss: 0.4568 - val_accuracy: 0.6962 - val_loss: 1.9553\n",
            "Epoch 18/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9198 - loss: 0.4521 - val_accuracy: 0.6878 - val_loss: 1.9233\n",
            "Epoch 19/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9205 - loss: 0.4063 - val_accuracy: 0.6926 - val_loss: 2.0147\n",
            "Epoch 20/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9227 - loss: 0.3927 - val_accuracy: 0.6992 - val_loss: 1.7422\n",
            "Epoch 21/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9231 - loss: 0.4133 - val_accuracy: 0.6940 - val_loss: 3.5718\n",
            "Epoch 22/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9215 - loss: 0.4010 - val_accuracy: 0.6955 - val_loss: 1.0456\n",
            "Epoch 23/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9229 - loss: 0.3361 - val_accuracy: 0.6910 - val_loss: 1.8083\n",
            "Epoch 24/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9230 - loss: 0.4051 - val_accuracy: 0.6981 - val_loss: 0.9154\n",
            "Epoch 25/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9250 - loss: 0.3830 - val_accuracy: 0.7036 - val_loss: 0.9083\n",
            "Epoch 26/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9223 - loss: 0.3819 - val_accuracy: 0.6885 - val_loss: 1.2219\n",
            "Epoch 27/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9257 - loss: 0.3174 - val_accuracy: 0.7041 - val_loss: 1.3498\n",
            "Epoch 28/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9254 - loss: 0.3304 - val_accuracy: 0.6970 - val_loss: 1.1196\n",
            "Epoch 29/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9273 - loss: 0.3120 - val_accuracy: 0.7050 - val_loss: 2.0778\n",
            "Epoch 30/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9274 - loss: 0.2887 - val_accuracy: 0.7220 - val_loss: 0.9481\n",
            "Epoch 31/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9282 - loss: 0.3101 - val_accuracy: 0.7241 - val_loss: 1.1724\n",
            "Epoch 32/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9241 - loss: 0.3347 - val_accuracy: 0.6847 - val_loss: 3.2183\n",
            "Epoch 33/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9311 - loss: 0.2881 - val_accuracy: 0.7047 - val_loss: 0.9352\n",
            "Epoch 34/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9283 - loss: 0.2827 - val_accuracy: 0.7005 - val_loss: 0.8531\n",
            "Epoch 35/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9279 - loss: 0.2719 - val_accuracy: 0.6894 - val_loss: 0.9878\n",
            "Epoch 36/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9304 - loss: 0.2691 - val_accuracy: 0.6963 - val_loss: 0.8194\n",
            "Epoch 37/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9278 - loss: 0.2635 - val_accuracy: 0.6979 - val_loss: 1.2098\n",
            "Epoch 38/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9271 - loss: 0.2762 - val_accuracy: 0.7010 - val_loss: 0.8908\n",
            "Epoch 39/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9322 - loss: 0.2383 - val_accuracy: 0.6841 - val_loss: 1.1689\n",
            "Epoch 40/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9298 - loss: 0.2212 - val_accuracy: 0.7018 - val_loss: 0.7236\n",
            "Epoch 41/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2184 - val_accuracy: 0.6987 - val_loss: 0.7921\n",
            "Epoch 42/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9305 - loss: 0.2360 - val_accuracy: 0.6908 - val_loss: 1.1402\n",
            "Epoch 43/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9324 - loss: 0.2216 - val_accuracy: 0.6921 - val_loss: 0.9432\n",
            "Epoch 44/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9325 - loss: 0.2121 - val_accuracy: 0.7105 - val_loss: 0.9759\n",
            "Epoch 45/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9303 - loss: 0.2388 - val_accuracy: 0.6852 - val_loss: 1.1386\n",
            "Epoch 46/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9296 - loss: 0.2327 - val_accuracy: 0.6926 - val_loss: 1.0326\n",
            "Epoch 47/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9294 - loss: 0.2144 - val_accuracy: 0.6842 - val_loss: 1.6146\n",
            "Epoch 48/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9324 - loss: 0.2119 - val_accuracy: 0.6885 - val_loss: 1.3370\n",
            "Epoch 49/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9323 - loss: 0.1915 - val_accuracy: 0.6890 - val_loss: 1.1806\n",
            "Epoch 50/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9353 - loss: 0.1829 - val_accuracy: 0.7162 - val_loss: 0.7653\n",
            "Epoch 51/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9333 - loss: 0.1992 - val_accuracy: 0.6884 - val_loss: 0.9949\n",
            "Epoch 52/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9348 - loss: 0.1825 - val_accuracy: 0.6973 - val_loss: 0.8666\n",
            "Epoch 53/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.1815 - val_accuracy: 0.6927 - val_loss: 0.9860\n",
            "Epoch 54/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9325 - loss: 0.1919 - val_accuracy: 0.6847 - val_loss: 1.1383\n",
            "Epoch 55/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1800 - val_accuracy: 0.6845 - val_loss: 1.2104\n",
            "Epoch 56/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9345 - loss: 0.1806 - val_accuracy: 0.6919 - val_loss: 0.8626\n",
            "Epoch 57/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9319 - loss: 0.1910 - val_accuracy: 0.6913 - val_loss: 0.9065\n",
            "Epoch 58/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1754 - val_accuracy: 0.6960 - val_loss: 0.7835\n",
            "Epoch 59/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.1690 - val_accuracy: 0.6925 - val_loss: 1.0396\n",
            "Epoch 60/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9365 - loss: 0.1694 - val_accuracy: 0.6884 - val_loss: 0.9509\n",
            "Epoch 61/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9381 - loss: 0.1652 - val_accuracy: 0.6841 - val_loss: 1.1394\n",
            "Epoch 62/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9373 - loss: 0.1646 - val_accuracy: 0.6893 - val_loss: 1.0024\n",
            "Epoch 63/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.1696 - val_accuracy: 0.6861 - val_loss: 0.8745\n",
            "Epoch 64/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1704 - val_accuracy: 0.6880 - val_loss: 0.8760\n",
            "Epoch 65/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.1700 - val_accuracy: 0.6935 - val_loss: 0.9928\n",
            "Epoch 66/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9336 - loss: 0.1728 - val_accuracy: 0.6854 - val_loss: 0.8930\n",
            "Epoch 67/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9385 - loss: 0.1644 - val_accuracy: 0.6854 - val_loss: 0.8321\n",
            "Epoch 68/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9384 - loss: 0.1658 - val_accuracy: 0.6842 - val_loss: 0.9123\n",
            "Epoch 69/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.1658 - val_accuracy: 0.6852 - val_loss: 0.7892\n",
            "Epoch 70/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9373 - loss: 0.1650 - val_accuracy: 0.6892 - val_loss: 0.7656\n",
            "Epoch 71/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.1698 - val_accuracy: 0.6928 - val_loss: 0.8238\n",
            "Epoch 72/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1668 - val_accuracy: 0.6853 - val_loss: 0.9043\n",
            "Epoch 73/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9396 - loss: 0.1640 - val_accuracy: 0.6874 - val_loss: 0.8625\n",
            "Epoch 74/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.1693 - val_accuracy: 0.6922 - val_loss: 0.8209\n",
            "Epoch 75/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.1640 - val_accuracy: 0.6849 - val_loss: 0.7960\n",
            "Epoch 76/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.1699 - val_accuracy: 0.6880 - val_loss: 1.1921\n",
            "Epoch 77/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.1730 - val_accuracy: 0.6842 - val_loss: 0.9667\n",
            "Epoch 78/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.1650 - val_accuracy: 0.6859 - val_loss: 0.9556\n",
            "Epoch 79/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.1639 - val_accuracy: 0.6872 - val_loss: 0.7899\n",
            "Epoch 80/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9361 - loss: 0.1695 - val_accuracy: 0.6888 - val_loss: 0.8949\n",
            "Epoch 81/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.1680 - val_accuracy: 0.6994 - val_loss: 0.7587\n",
            "Epoch 82/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.1624 - val_accuracy: 0.6866 - val_loss: 0.8137\n",
            "Epoch 83/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.1661 - val_accuracy: 0.6858 - val_loss: 0.7584\n",
            "Epoch 84/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.1643 - val_accuracy: 0.6851 - val_loss: 0.8570\n",
            "Epoch 85/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9372 - loss: 0.1672 - val_accuracy: 0.6849 - val_loss: 2.5430\n",
            "Epoch 86/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.1877 - val_accuracy: 0.6875 - val_loss: 0.8717\n",
            "Epoch 87/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9372 - loss: 0.1657 - val_accuracy: 0.6946 - val_loss: 0.8661\n",
            "Epoch 88/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.1685 - val_accuracy: 0.7022 - val_loss: 0.7722\n",
            "Epoch 89/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9377 - loss: 0.1643 - val_accuracy: 0.6876 - val_loss: 0.9250\n",
            "Epoch 90/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.1643 - val_accuracy: 0.6852 - val_loss: 0.7972\n",
            "Epoch 91/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9344 - loss: 0.1672 - val_accuracy: 0.6888 - val_loss: 0.9519\n",
            "Epoch 92/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1652 - val_accuracy: 0.6858 - val_loss: 0.8281\n",
            "Epoch 93/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.1635 - val_accuracy: 0.6901 - val_loss: 0.8616\n",
            "Epoch 94/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9369 - loss: 0.1671 - val_accuracy: 0.6866 - val_loss: 0.9438\n",
            "Epoch 95/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.1635 - val_accuracy: 0.6879 - val_loss: 0.8562\n",
            "Epoch 96/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.1647 - val_accuracy: 0.6845 - val_loss: 0.8932\n",
            "Epoch 97/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.1629 - val_accuracy: 0.6853 - val_loss: 0.8148\n",
            "Epoch 98/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.1611 - val_accuracy: 0.6908 - val_loss: 0.8070\n",
            "Epoch 99/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9355 - loss: 0.1696 - val_accuracy: 0.6958 - val_loss: 0.7656\n",
            "Epoch 100/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.1676 - val_accuracy: 0.6878 - val_loss: 0.8971\n",
            "Epoch 101/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1636 - val_accuracy: 0.6847 - val_loss: 0.8767\n",
            "Epoch 102/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.1654 - val_accuracy: 0.6852 - val_loss: 0.8475\n",
            "Epoch 103/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.1635 - val_accuracy: 0.6877 - val_loss: 0.8724\n",
            "Epoch 104/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9387 - loss: 0.1607 - val_accuracy: 0.6899 - val_loss: 1.0815\n",
            "Epoch 105/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1670 - val_accuracy: 0.6865 - val_loss: 0.8268\n",
            "Epoch 106/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.1659 - val_accuracy: 0.6852 - val_loss: 0.9023\n",
            "Epoch 107/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.1730 - val_accuracy: 0.6876 - val_loss: 0.8338\n",
            "Epoch 108/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.1615 - val_accuracy: 0.6849 - val_loss: 0.9504\n",
            "Epoch 109/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.1669 - val_accuracy: 0.6947 - val_loss: 0.7648\n",
            "Epoch 110/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9382 - loss: 0.1614 - val_accuracy: 0.6882 - val_loss: 0.7535\n",
            "Epoch 111/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1648 - val_accuracy: 0.6855 - val_loss: 0.8495\n",
            "Epoch 112/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.1677 - val_accuracy: 0.6889 - val_loss: 0.8634\n",
            "Epoch 113/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.1668 - val_accuracy: 0.6849 - val_loss: 1.0203\n",
            "Epoch 114/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.1689 - val_accuracy: 0.6897 - val_loss: 0.9805\n",
            "Epoch 115/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9390 - loss: 0.1588 - val_accuracy: 0.6895 - val_loss: 0.7572\n",
            "Epoch 116/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9360 - loss: 0.1660 - val_accuracy: 0.6880 - val_loss: 0.8223\n",
            "Epoch 117/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.1636 - val_accuracy: 0.6854 - val_loss: 0.8375\n",
            "Epoch 118/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9358 - loss: 0.1681 - val_accuracy: 0.6910 - val_loss: 0.7896\n",
            "Epoch 119/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.1638 - val_accuracy: 0.6893 - val_loss: 0.8409\n",
            "Epoch 120/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.1676 - val_accuracy: 0.6924 - val_loss: 0.9075\n",
            "Epoch 121/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9382 - loss: 0.1667 - val_accuracy: 0.6951 - val_loss: 0.7881\n",
            "Epoch 122/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9357 - loss: 0.1698 - val_accuracy: 0.6855 - val_loss: 0.8582\n",
            "Epoch 123/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9357 - loss: 0.1677 - val_accuracy: 0.6847 - val_loss: 0.9378\n",
            "Epoch 124/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.1663 - val_accuracy: 0.6855 - val_loss: 0.7975\n",
            "Epoch 125/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.1688 - val_accuracy: 0.6862 - val_loss: 1.0651\n",
            "Epoch 126/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9365 - loss: 0.1628 - val_accuracy: 0.6884 - val_loss: 0.8551\n",
            "Epoch 127/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9361 - loss: 0.1639 - val_accuracy: 0.6888 - val_loss: 0.7944\n",
            "Epoch 128/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.1648 - val_accuracy: 0.6847 - val_loss: 0.9002\n",
            "Epoch 129/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.1625 - val_accuracy: 0.6867 - val_loss: 0.8154\n",
            "Epoch 130/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.1628 - val_accuracy: 0.6892 - val_loss: 0.8745\n",
            "Epoch 131/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1638 - val_accuracy: 0.6927 - val_loss: 0.7393\n",
            "Epoch 132/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9341 - loss: 0.1646 - val_accuracy: 0.6872 - val_loss: 0.9430\n",
            "Epoch 133/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9343 - loss: 0.1682 - val_accuracy: 0.6886 - val_loss: 0.7462\n",
            "Epoch 134/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.1614 - val_accuracy: 0.6841 - val_loss: 0.8400\n",
            "Epoch 135/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.1634 - val_accuracy: 0.6872 - val_loss: 0.8624\n",
            "Epoch 136/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9366 - loss: 0.1667 - val_accuracy: 0.6878 - val_loss: 0.7977\n",
            "Epoch 137/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9344 - loss: 0.1673 - val_accuracy: 0.6847 - val_loss: 0.8806\n",
            "Epoch 138/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.1635 - val_accuracy: 0.6887 - val_loss: 0.8479\n",
            "Epoch 139/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9350 - loss: 0.1671 - val_accuracy: 0.6946 - val_loss: 0.9238\n",
            "Epoch 140/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9376 - loss: 0.1630 - val_accuracy: 0.6875 - val_loss: 0.8487\n",
            "Epoch 141/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9369 - loss: 0.1618 - val_accuracy: 0.6848 - val_loss: 0.8277\n",
            "Epoch 142/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9371 - loss: 0.1658 - val_accuracy: 0.6880 - val_loss: 0.8727\n",
            "Epoch 143/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1667 - val_accuracy: 0.6894 - val_loss: 0.9002\n",
            "Epoch 144/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.1633 - val_accuracy: 0.6878 - val_loss: 0.7917\n",
            "Epoch 145/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9353 - loss: 0.1660 - val_accuracy: 0.6873 - val_loss: 0.8199\n",
            "Epoch 146/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9372 - loss: 0.1619 - val_accuracy: 0.6846 - val_loss: 0.8049\n",
            "Epoch 147/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9384 - loss: 0.1601 - val_accuracy: 0.6848 - val_loss: 0.9886\n",
            "Epoch 148/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.1681 - val_accuracy: 0.6897 - val_loss: 0.8735\n",
            "Epoch 149/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.1648 - val_accuracy: 0.6924 - val_loss: 0.8679\n",
            "Epoch 150/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9364 - loss: 0.1622 - val_accuracy: 0.6893 - val_loss: 0.9341\n",
            "Epoch 151/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.1615 - val_accuracy: 0.6846 - val_loss: 0.9344\n",
            "Epoch 152/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9339 - loss: 0.1729 - val_accuracy: 0.6966 - val_loss: 0.8374\n",
            "Epoch 153/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 2ms/step - accuracy: 0.9344 - loss: 0.1659 - val_accuracy: 0.6884 - val_loss: 0.8294\n",
            "Epoch 154/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9340 - loss: 0.1670 - val_accuracy: 0.6874 - val_loss: 0.8104\n",
            "Epoch 155/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9346 - loss: 0.1694 - val_accuracy: 0.6848 - val_loss: 0.9001\n",
            "Epoch 156/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9369 - loss: 0.1632 - val_accuracy: 0.6899 - val_loss: 0.8116\n",
            "Epoch 157/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1612 - val_accuracy: 0.6941 - val_loss: 0.8433\n",
            "Epoch 158/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9394 - loss: 0.1578 - val_accuracy: 0.6896 - val_loss: 0.8702\n",
            "Epoch 159/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9349 - loss: 0.1678 - val_accuracy: 0.6995 - val_loss: 0.8454\n",
            "Epoch 160/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.1645 - val_accuracy: 0.6885 - val_loss: 0.8872\n",
            "Epoch 161/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9368 - loss: 0.1637 - val_accuracy: 0.6842 - val_loss: 0.8618\n",
            "Epoch 162/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9365 - loss: 0.1633 - val_accuracy: 0.6871 - val_loss: 0.9489\n",
            "Epoch 163/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9355 - loss: 0.1649 - val_accuracy: 0.6861 - val_loss: 0.9992\n",
            "Epoch 164/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.1630 - val_accuracy: 0.6846 - val_loss: 0.8929\n",
            "Epoch 165/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.1608 - val_accuracy: 0.6855 - val_loss: 0.9779\n",
            "Epoch 166/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9367 - loss: 0.1646 - val_accuracy: 0.6844 - val_loss: 0.9506\n",
            "Epoch 167/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9352 - loss: 0.1669 - val_accuracy: 0.6852 - val_loss: 0.9290\n",
            "Epoch 168/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9383 - loss: 0.1609 - val_accuracy: 0.6904 - val_loss: 0.9228\n",
            "Epoch 169/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9334 - loss: 0.1675 - val_accuracy: 0.6858 - val_loss: 0.8245\n",
            "Epoch 170/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9352 - loss: 0.1662 - val_accuracy: 0.6863 - val_loss: 0.9033\n",
            "Epoch 171/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9347 - loss: 0.1630 - val_accuracy: 0.6882 - val_loss: 0.8944\n",
            "Epoch 172/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9360 - loss: 0.1665 - val_accuracy: 0.6848 - val_loss: 0.8875\n",
            "Epoch 173/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.1645 - val_accuracy: 0.6876 - val_loss: 0.8987\n",
            "Epoch 174/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9380 - loss: 0.1638 - val_accuracy: 0.6865 - val_loss: 0.8978\n",
            "Epoch 175/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1673 - val_accuracy: 0.6854 - val_loss: 0.8910\n",
            "Epoch 176/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9377 - loss: 0.1618 - val_accuracy: 0.6838 - val_loss: 0.9429\n",
            "Epoch 177/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9374 - loss: 0.1604 - val_accuracy: 0.6871 - val_loss: 0.8538\n",
            "Epoch 178/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9388 - loss: 0.1625 - val_accuracy: 0.6848 - val_loss: 0.8905\n",
            "Epoch 179/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.1626 - val_accuracy: 0.6858 - val_loss: 0.9702\n",
            "Epoch 180/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9341 - loss: 0.1671 - val_accuracy: 0.6969 - val_loss: 0.8173\n",
            "Epoch 181/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9369 - loss: 0.1637 - val_accuracy: 0.6855 - val_loss: 0.9358\n",
            "Epoch 182/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9346 - loss: 0.1656 - val_accuracy: 0.6875 - val_loss: 0.8366\n",
            "Epoch 183/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.1624 - val_accuracy: 0.6946 - val_loss: 0.9014\n",
            "Epoch 184/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9369 - loss: 0.1633 - val_accuracy: 0.6889 - val_loss: 0.9654\n",
            "Epoch 185/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1674 - val_accuracy: 0.6849 - val_loss: 0.9381\n",
            "Epoch 186/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9366 - loss: 0.1616 - val_accuracy: 0.6840 - val_loss: 0.9530\n",
            "Epoch 187/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9367 - loss: 0.1614 - val_accuracy: 0.6946 - val_loss: 0.8102\n",
            "Epoch 188/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1629 - val_accuracy: 0.6968 - val_loss: 0.8219\n",
            "Epoch 189/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9374 - loss: 0.1598 - val_accuracy: 0.6849 - val_loss: 0.8168\n",
            "Epoch 190/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9331 - loss: 0.1694 - val_accuracy: 0.6865 - val_loss: 0.8874\n",
            "Epoch 191/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 3ms/step - accuracy: 0.9359 - loss: 0.1646 - val_accuracy: 0.6877 - val_loss: 0.8627\n",
            "Epoch 192/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9362 - loss: 0.1657 - val_accuracy: 0.6877 - val_loss: 0.8100\n",
            "Epoch 193/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9349 - loss: 0.1666 - val_accuracy: 0.6924 - val_loss: 0.9030\n",
            "Epoch 194/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9378 - loss: 0.1616 - val_accuracy: 0.6921 - val_loss: 1.2040\n",
            "Epoch 195/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9344 - loss: 0.1672 - val_accuracy: 0.6928 - val_loss: 0.9201\n",
            "Epoch 196/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.9370 - loss: 0.1632 - val_accuracy: 0.6872 - val_loss: 0.8573\n",
            "Epoch 197/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9356 - loss: 0.1667 - val_accuracy: 0.6914 - val_loss: 0.8966\n",
            "Epoch 198/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.9375 - loss: 0.1621 - val_accuracy: 0.6937 - val_loss: 0.8886\n",
            "Epoch 199/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9359 - loss: 0.1655 - val_accuracy: 0.6840 - val_loss: 0.9041\n",
            "Epoch 200/200\n",
            "\u001b[1m1131/1131\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 3ms/step - accuracy: 0.9372 - loss: 0.1594 - val_accuracy: 0.6854 - val_loss: 0.9154\n",
            "Best epoch value is:  6\n"
          ]
        }
      ],
      "source": [
        "# creating model with optimimum parameters\n",
        "model = tuner.hypermodel.build(best_hps)\n",
        "# model training\n",
        "history = model.fit(X, y, epochs=200, validation_split=0.2)\n",
        "# fining the optimum epochs\n",
        "val_acc_per_epoch = history.history['val_accuracy']\n",
        "best_epoch = val_acc_per_epoch.index(max(val_acc_per_epoch)) + 1\n",
        "print('Best epoch value is: ' ,best_epoch)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9qwUXRzljCEN"
      },
      "source": [
        "As you can see, the tuner has returned 38 as the optimum value for the model.\n",
        "\n",
        "### Training the model with optimum parameters\n",
        "Now, we will use optimum numbers returned by the Keras tuner for several nodes and epochs to train the model and see the result."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8JzvRwrpjICi",
        "outputId": "436ee2ad-7bcf-4388-9e5c-9fd7f1921b97"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7781 - loss: 10.9346\n",
            "Epoch 2/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8361 - loss: 1.9220\n",
            "Epoch 3/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8450 - loss: 1.8017\n",
            "Epoch 4/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8458 - loss: 1.9960\n",
            "Epoch 5/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8492 - loss: 2.2341\n",
            "Epoch 6/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8497 - loss: 1.7328\n",
            "Epoch 7/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8522 - loss: 1.5119\n",
            "Epoch 8/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8493 - loss: 1.7474\n",
            "Epoch 9/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8476 - loss: 1.9315\n",
            "Epoch 10/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8547 - loss: 1.4489\n",
            "Epoch 11/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8491 - loss: 1.9092\n",
            "Epoch 12/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8625 - loss: 1.3079\n",
            "Epoch 13/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8539 - loss: 1.5410\n",
            "Epoch 14/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8590 - loss: 1.1312\n",
            "Epoch 15/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8593 - loss: 1.2131\n",
            "Epoch 16/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8576 - loss: 1.2968\n",
            "Epoch 17/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8532 - loss: 1.8915\n",
            "Epoch 18/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8548 - loss: 1.2505\n",
            "Epoch 19/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8505 - loss: 1.5219\n",
            "Epoch 20/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8575 - loss: 1.4468\n",
            "Epoch 21/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8588 - loss: 1.4404\n",
            "Epoch 22/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8579 - loss: 1.4970\n",
            "Epoch 23/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 1ms/step - accuracy: 0.8609 - loss: 1.2751\n",
            "Epoch 24/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8648 - loss: 1.3465\n",
            "Epoch 25/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8665 - loss: 1.1400\n",
            "Epoch 26/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8584 - loss: 1.3586\n",
            "Epoch 27/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8541 - loss: 1.7767\n",
            "Epoch 28/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8615 - loss: 1.0580\n",
            "Epoch 29/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8553 - loss: 1.2934\n",
            "Epoch 30/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8652 - loss: 1.2561\n",
            "Epoch 31/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8591 - loss: 1.3989\n",
            "Epoch 32/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8650 - loss: 1.1771\n",
            "Epoch 33/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 1ms/step - accuracy: 0.8681 - loss: 1.0026\n",
            "Epoch 34/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 1ms/step - accuracy: 0.8621 - loss: 1.2650\n",
            "Epoch 35/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8568 - loss: 1.6072\n",
            "Epoch 36/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.8607 - loss: 1.1158\n",
            "Epoch 37/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8608 - loss: 1.4982\n",
            "Epoch 38/38\n",
            "\u001b[1m989/989\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 2ms/step - accuracy: 0.8670 - loss: 1.0349\n",
            "\u001b[1m424/424\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8882 - loss: 0.6563\n",
            "Test Accuracy: 0.8880860805511475\n"
          ]
        }
      ],
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "# adding input layer with 16 nodes, providing the input shape as a tuple\n",
        "model.add(InputLayer(shape=(16,)))  # Changed line\n",
        "# adding hidden layer with 10 nodes\n",
        "model.add(Dense(54, activation='relu', kernel_initializer='he_normal'))\n",
        "# adding output layer\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "# model trained\n",
        "model.fit(X_train, y_train, epochs=38)\n",
        "\n",
        "# evaluate the model with accuracy metrics\n",
        "evaluate = model.evaluate(X_test, y_test)\n",
        "print('Test Accuracy:', evaluate[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T-A6pSRdjMHm"
      },
      "source": [
        "As you can see, this time, we got an accuracy score of 88%, which means our model has performed a little better than the previous one, where we get an accuracy of 85%.\n",
        "\n",
        "### Multiclass classification using TensorFlow\n",
        "Now, we will use TensorFlow for multiclass classification using Neural networks. In this section, we will use a dataset from a higher education institution related to students enrolled in different undergraduate degrees, such as agronomy, design, education, nursing, journalism, management, social service, and technologies. The data is used to build classification models to predict students’ dropout and academic success. So, there are three output categories; enrolled, dropout, and graduate. You can read about the dataset and download it from this link.\n",
        "\n",
        "### Importing and exploring the dataset\n",
        "First, we import the dataset and print a few rows to familiarize ourselves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 307
        },
        "id": "4sTrvOR7jS5r",
        "outputId": "56f778d9-3197-4e9a-d77b-0d5a346ae054"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Marital status  Application mode  Application order  Course  \\\n",
              "0               1                 8                  5       2   \n",
              "1               1                 6                  1      11   \n",
              "2               1                 1                  5       5   \n",
              "3               1                 8                  2      15   \n",
              "4               2                12                  1       3   \n",
              "\n",
              "   Daytime/evening attendance  Previous qualification  Nacionality  \\\n",
              "0                           1                       1            1   \n",
              "1                           1                       1            1   \n",
              "2                           1                       1            1   \n",
              "3                           1                       1            1   \n",
              "4                           0                       1            1   \n",
              "\n",
              "   Mother's qualification  Father's qualification  Mother's occupation  ...  \\\n",
              "0                      13                      10                    6  ...   \n",
              "1                       1                       3                    4  ...   \n",
              "2                      22                      27                   10  ...   \n",
              "3                      23                      27                    6  ...   \n",
              "4                      22                      28                   10  ...   \n",
              "\n",
              "   Curricular units 2nd sem (credited)  Curricular units 2nd sem (enrolled)  \\\n",
              "0                                    0                                    0   \n",
              "1                                    0                                    6   \n",
              "2                                    0                                    6   \n",
              "3                                    0                                    6   \n",
              "4                                    0                                    6   \n",
              "\n",
              "   Curricular units 2nd sem (evaluations)  \\\n",
              "0                                       0   \n",
              "1                                       6   \n",
              "2                                       0   \n",
              "3                                      10   \n",
              "4                                       6   \n",
              "\n",
              "   Curricular units 2nd sem (approved)  Curricular units 2nd sem (grade)  \\\n",
              "0                                    0                          0.000000   \n",
              "1                                    6                         13.666667   \n",
              "2                                    0                          0.000000   \n",
              "3                                    5                         12.400000   \n",
              "4                                    6                         13.000000   \n",
              "\n",
              "   Curricular units 2nd sem (without evaluations)  Unemployment rate  \\\n",
              "0                                               0               10.8   \n",
              "1                                               0               13.9   \n",
              "2                                               0               10.8   \n",
              "3                                               0                9.4   \n",
              "4                                               0               13.9   \n",
              "\n",
              "   Inflation rate   GDP    Target  \n",
              "0             1.4  1.74   Dropout  \n",
              "1            -0.3  0.79  Graduate  \n",
              "2             1.4  1.74   Dropout  \n",
              "3            -0.8 -3.12  Graduate  \n",
              "4            -0.3  0.79  Graduate  \n",
              "\n",
              "[5 rows x 35 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-f49f6fa8-3329-4292-9393-20313835ab6b\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Marital status</th>\n",
              "      <th>Application mode</th>\n",
              "      <th>Application order</th>\n",
              "      <th>Course</th>\n",
              "      <th>Daytime/evening attendance</th>\n",
              "      <th>Previous qualification</th>\n",
              "      <th>Nacionality</th>\n",
              "      <th>Mother's qualification</th>\n",
              "      <th>Father's qualification</th>\n",
              "      <th>Mother's occupation</th>\n",
              "      <th>...</th>\n",
              "      <th>Curricular units 2nd sem (credited)</th>\n",
              "      <th>Curricular units 2nd sem (enrolled)</th>\n",
              "      <th>Curricular units 2nd sem (evaluations)</th>\n",
              "      <th>Curricular units 2nd sem (approved)</th>\n",
              "      <th>Curricular units 2nd sem (grade)</th>\n",
              "      <th>Curricular units 2nd sem (without evaluations)</th>\n",
              "      <th>Unemployment rate</th>\n",
              "      <th>Inflation rate</th>\n",
              "      <th>GDP</th>\n",
              "      <th>Target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>13</td>\n",
              "      <td>10</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>1</td>\n",
              "      <td>11</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>4</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.666667</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>27</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>10.8</td>\n",
              "      <td>1.4</td>\n",
              "      <td>1.74</td>\n",
              "      <td>Dropout</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>2</td>\n",
              "      <td>15</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>23</td>\n",
              "      <td>27</td>\n",
              "      <td>6</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>5</td>\n",
              "      <td>12.400000</td>\n",
              "      <td>0</td>\n",
              "      <td>9.4</td>\n",
              "      <td>-0.8</td>\n",
              "      <td>-3.12</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>2</td>\n",
              "      <td>12</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>22</td>\n",
              "      <td>28</td>\n",
              "      <td>10</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>6</td>\n",
              "      <td>13.000000</td>\n",
              "      <td>0</td>\n",
              "      <td>13.9</td>\n",
              "      <td>-0.3</td>\n",
              "      <td>0.79</td>\n",
              "      <td>Graduate</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 35 columns</p>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f49f6fa8-3329-4292-9393-20313835ab6b')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-f49f6fa8-3329-4292-9393-20313835ab6b button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-f49f6fa8-3329-4292-9393-20313835ab6b');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-582c504e-f884-4b17-bc1d-0f715df36473\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-582c504e-f884-4b17-bc1d-0f715df36473')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-582c504e-f884-4b17-bc1d-0f715df36473 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "variable_name": "dataset"
            }
          },
          "metadata": {},
          "execution_count": 53
        }
      ],
      "source": [
        "# importing the dataset\n",
        "dataset = pd.read_csv('./dataset/bank+marketing/bank/dataset.csv')\n",
        "# heading of dataset\n",
        "dataset.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TeiDMLGijYm1"
      },
      "source": [
        "As you can see, there is a total of 35 columns and 34 of which are input variables. Let us also use the info() method to get more information about the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 54,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Si2Ov2VPjbyY",
        "outputId": "0d523df0-80cf-4fe3-990b-1249b003d50b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 4424 entries, 0 to 4423\n",
            "Data columns (total 35 columns):\n",
            " #   Column                                          Non-Null Count  Dtype  \n",
            "---  ------                                          --------------  -----  \n",
            " 0   Marital status                                  4424 non-null   int64  \n",
            " 1   Application mode                                4424 non-null   int64  \n",
            " 2   Application order                               4424 non-null   int64  \n",
            " 3   Course                                          4424 non-null   int64  \n",
            " 4   Daytime/evening attendance                      4424 non-null   int64  \n",
            " 5   Previous qualification                          4424 non-null   int64  \n",
            " 6   Nacionality                                     4424 non-null   int64  \n",
            " 7   Mother's qualification                          4424 non-null   int64  \n",
            " 8   Father's qualification                          4424 non-null   int64  \n",
            " 9   Mother's occupation                             4424 non-null   int64  \n",
            " 10  Father's occupation                             4424 non-null   int64  \n",
            " 11  Displaced                                       4424 non-null   int64  \n",
            " 12  Educational special needs                       4424 non-null   int64  \n",
            " 13  Debtor                                          4424 non-null   int64  \n",
            " 14  Tuition fees up to date                         4424 non-null   int64  \n",
            " 15  Gender                                          4424 non-null   int64  \n",
            " 16  Scholarship holder                              4424 non-null   int64  \n",
            " 17  Age at enrollment                               4424 non-null   int64  \n",
            " 18  International                                   4424 non-null   int64  \n",
            " 19  Curricular units 1st sem (credited)             4424 non-null   int64  \n",
            " 20  Curricular units 1st sem (enrolled)             4424 non-null   int64  \n",
            " 21  Curricular units 1st sem (evaluations)          4424 non-null   int64  \n",
            " 22  Curricular units 1st sem (approved)             4424 non-null   int64  \n",
            " 23  Curricular units 1st sem (grade)                4424 non-null   float64\n",
            " 24  Curricular units 1st sem (without evaluations)  4424 non-null   int64  \n",
            " 25  Curricular units 2nd sem (credited)             4424 non-null   int64  \n",
            " 26  Curricular units 2nd sem (enrolled)             4424 non-null   int64  \n",
            " 27  Curricular units 2nd sem (evaluations)          4424 non-null   int64  \n",
            " 28  Curricular units 2nd sem (approved)             4424 non-null   int64  \n",
            " 29  Curricular units 2nd sem (grade)                4424 non-null   float64\n",
            " 30  Curricular units 2nd sem (without evaluations)  4424 non-null   int64  \n",
            " 31  Unemployment rate                               4424 non-null   float64\n",
            " 32  Inflation rate                                  4424 non-null   float64\n",
            " 33  GDP                                             4424 non-null   float64\n",
            " 34  Target                                          4424 non-null   object \n",
            "dtypes: float64(5), int64(29), object(1)\n",
            "memory usage: 1.2+ MB\n"
          ]
        }
      ],
      "source": [
        "#info method\n",
        "dataset.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WzIJEJPojeoV"
      },
      "source": [
        "As you can see, our dataset contains 4424 observations, all of which have numeric values except the output class. So, let us now convert the object type object into numeric values."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 55,
      "metadata": {
        "id": "HstvKuSBlzE2"
      },
      "outputs": [],
      "source": [
        "# importing the module\n",
        "from sklearn import preprocessing\n",
        "\n",
        "# creating labing encoding object\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "\n",
        "# Encode labels in multiple columns\n",
        "dataset['Target']= label_encoder.fit_transform(dataset['Target'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eEIAlK1Bl0tv"
      },
      "source": [
        "Now, the data is ready to be used to train the model\n",
        "\n",
        "### Splitting the dataset\n",
        "Now, we will divide the dataset into input variables and output variables."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 56,
      "metadata": {
        "id": "mKmhKEGhl2i1"
      },
      "outputs": [],
      "source": [
        "# dividing the dataset\n",
        "X = dataset.drop('Target', axis=1)\n",
        "y=dataset['Target']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tyca567Nl39w"
      },
      "source": [
        "The next step is to split the data into the testing and training parts.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "sqhKTvrql5y_"
      },
      "outputs": [],
      "source": [
        "# splitting the dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9JuJiHL0l75K"
      },
      "source": [
        "As you can see, we have assigned 25% of the dataset to the testing part and the remaining 75% to the training part.\n",
        "\n",
        "### Building Neural Network for multiclass classification\n",
        "Let us initialize the model with the input, hidden, and output layers."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 58,
      "metadata": {
        "id": "hLVM0d2Al-MZ"
      },
      "outputs": [],
      "source": [
        "# define model\n",
        "model = Sequential()\n",
        "# adding input layer with 34 nodes, providing input_shape as a tuple\n",
        "model.add(InputLayer(shape=(34,)))  # Changed line\n",
        "# adding hidden layer with 10 nodes\n",
        "model.add(Dense(10, activation='relu', kernel_initializer='he_normal'))\n",
        "# adding output layer\n",
        "model.add(Dense(3, activation='softmax'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfx9MCzsmDM3"
      },
      "source": [
        "Compiling the model\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dvu18j1XmCc-",
        "outputId": "f6c552ce-de92-4a00-9774-17f7f31acb77"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 9ms/step - accuracy: 0.3223 - loss: 4.4780\n",
            "Epoch 2/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.5405 - loss: 1.1155\n",
            "Epoch 3/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6058 - loss: 0.9579\n",
            "Epoch 4/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6484 - loss: 0.8948\n",
            "Epoch 5/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6646 - loss: 0.8538\n",
            "Epoch 6/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6800 - loss: 0.8023\n",
            "Epoch 7/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6769 - loss: 0.7911\n",
            "Epoch 8/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6809 - loss: 0.7615\n",
            "Epoch 9/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.6896 - loss: 0.7401\n",
            "Epoch 10/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7004 - loss: 0.7064\n",
            "Epoch 11/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7150 - loss: 0.6990\n",
            "Epoch 12/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7141 - loss: 0.6712\n",
            "Epoch 13/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7374 - loss: 0.6436\n",
            "Epoch 14/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7308 - loss: 0.6513\n",
            "Epoch 15/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.7278 - loss: 0.6503\n",
            "Epoch 16/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.7379 - loss: 0.6358\n",
            "Epoch 17/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7517 - loss: 0.6071\n",
            "Epoch 18/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7514 - loss: 0.6031\n",
            "Epoch 19/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7276 - loss: 0.6448\n",
            "Epoch 20/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7361 - loss: 0.6196\n",
            "Epoch 21/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7369 - loss: 0.6201\n",
            "Epoch 22/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7523 - loss: 0.5943\n",
            "Epoch 23/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7470 - loss: 0.6019\n",
            "Epoch 24/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7435 - loss: 0.6193\n",
            "Epoch 25/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7688 - loss: 0.5872\n",
            "Epoch 26/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7520 - loss: 0.6117\n",
            "Epoch 27/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7527 - loss: 0.5932\n",
            "Epoch 28/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7367 - loss: 0.6207\n",
            "Epoch 29/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7492 - loss: 0.6063\n",
            "Epoch 30/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7579 - loss: 0.5830\n",
            "Epoch 31/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7662 - loss: 0.5892\n",
            "Epoch 32/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7505 - loss: 0.5903\n",
            "Epoch 33/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7472 - loss: 0.6084\n",
            "Epoch 34/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7638 - loss: 0.5777\n",
            "Epoch 35/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7582 - loss: 0.6011\n",
            "Epoch 36/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7679 - loss: 0.5770\n",
            "Epoch 37/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7602 - loss: 0.5851\n",
            "Epoch 38/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7757 - loss: 0.5626\n",
            "Epoch 39/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7658 - loss: 0.5873\n",
            "Epoch 40/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7811 - loss: 0.5602\n",
            "Epoch 41/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7648 - loss: 0.5829\n",
            "Epoch 42/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7537 - loss: 0.5879\n",
            "Epoch 43/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7704 - loss: 0.5624\n",
            "Epoch 44/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7596 - loss: 0.5824\n",
            "Epoch 45/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7642 - loss: 0.5831\n",
            "Epoch 46/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7727 - loss: 0.5892\n",
            "Epoch 47/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7564 - loss: 0.5822\n",
            "Epoch 48/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7742 - loss: 0.5624\n",
            "Epoch 49/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7752 - loss: 0.5598\n",
            "Epoch 50/50\n",
            "\u001b[1m104/104\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.7657 - loss: 0.5694\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7a28b6a5d2d0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ],
      "source": [
        "# compile the model\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "# fit the model\n",
        "model.fit(X_train, y_train, epochs=50)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PhOjoQGomE1q"
      },
      "source": [
        "As you can see, we have used spare_categorical_crossentropy as our loss. Training a neural network involves passing data through the model and comparing predictions with ground truth labels. A loss function makes this comparison, and in the case of the multiclass classification problem, we used spare_categorical_crossentropy. We also fixed the epoch value to 50. You can change it to get optimum results.\n",
        "\n",
        "Let us evaluate the model by testing and finding the accuracy score."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x9vLCBqSmGbO",
        "outputId": "fe2b5be4-9758-44d6-b14a-ae2dcb49eadc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m35/35\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.7588 - loss: 0.5867\n",
            "Test Accuracy: 0.7685352563858032\n"
          ]
        }
      ],
      "source": [
        "# evaluate the model\n",
        "evaluate = model.evaluate(X_test, y_test)\n",
        "# printing evaluate accuracy\n",
        "print('Test Accuracy:', evaluate[1])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5OgLiyjWmIPl"
      },
      "source": [
        "As you can see, we get an accuracy score of 76%, which means the model predicts 76% of the testing data correctly.\n",
        "\n",
        "You can use the tunning parameter method to find the optimum parameters to get better results, as we did in the above section."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rudArIobmJpS"
      },
      "source": [
        "### Summary\n",
        "Neural networks are a series of algorithms that mimic the operations of a human brain to recognize relationships between vast amounts of data. You can use them for classification, regression, image recognition, forecasting, marketing research, and many more. This article taught us how to use TensorFlow to build a neural network to solve a binary and multiclass classification problem."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}